{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import svm, datasets\n",
    "import scipy.io as scp\n",
    "\n",
    "#from scipy import loadmat\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    " \n",
    "#from tensorflow.keras import optimizers\n",
    "#from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    " \n",
    "    \n",
    "    \n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D,Dropout,SeparableConv2D\n",
    "from tensorflow.keras.layers import Conv1D,AveragePooling1D,AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "#from keras.utils import layer_utils\n",
    "from tensorflow.python.keras.utils import layer_utils\n",
    "from tensorflow.python.keras.utils.data_utils import get_file\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    " \n",
    "from IPython.display import SVG\n",
    "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "\n",
    "import tensorflow.python.keras.backend as K\n",
    "import math\n",
    "from matplotlib.pyplot import imshow\n",
    "#import pydot\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Net(input_shape):\n",
    "    \"\"\"\n",
    "    Implementation of the HappyModel.\n",
    "    \n",
    "    TESTA OPZIONE SeparableConv2D!!\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Feel free to use the suggested outline in the text above to get started, and run through the whole\n",
    "    # exercise (including the later portions of this notebook) once. The come back also try out other\n",
    "    # network architectures as well. \n",
    "        # Define the input placeholder as a tensor with shape input_shape. Think of this as your input image!\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding: pads the border of X_input with zeroes\n",
    "    X = X_input\n",
    "\n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    #X = DepthwiseConv2D(NUMBER_OF_CHANNELS, (1, 7), name='conv0')(X)  \n",
    "    X = Conv2D(kernel_size =(1, 7), filters = NUMBER_OF_CHANNELS, strides=(1, 1), padding = 'same', name='conv0')(X)  \n",
    "    X = BatchNormalization(axis=3, name='bn0')(X)\n",
    "    X = Activation('relu',name='relu_0')(X)\n",
    "\n",
    "    # AVGPOOL\n",
    "    #X = MaxPooling2D((2, 2), name='max_pool1')(X)\n",
    "    X = AveragePooling2D((1, 2),strides=(1, 2),padding='valid', name='avg_pool0')(X)\n",
    "    #MaxPooling2D((2, 2),strides=(2, 2), name='max_pool0')(X) \n",
    "    \n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(64, (1, 10), strides=(1, 2),padding = 'same', name='conv1')(X)\n",
    "    X = BatchNormalization(axis=3, name='bn1')(X)\n",
    "    X = Activation('relu',name='relu_1')(X)\n",
    "\n",
    "    # MAXPOOL\n",
    "    #X = MaxPooling2D((2, 2),strides=(2, 1), name='max_pool1',)(X)\n",
    "    X = MaxPooling2D((1, 2),name='max_pool1',)(X)\n",
    "    \n",
    "    \n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(80, (1, 13), strides=(1, 1), padding = 'same',name='conv2')(X)    #IL FILTRO ERA 13 13 !!!!\n",
    "    X = BatchNormalization(axis=3, name='bn2')(X)\n",
    "    X = Activation('relu',name='relu_2')(X)\n",
    "\n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((1, 2), name='max_pool2')(X)\n",
    "    \n",
    "   \n",
    "    #X = Conv2D(80, (10, 1), strides=(1, 1), dilation_rate=(5, 1), padding='same', name='conv3_TC')(X)    #IL FILTRO ERA 13 13 !!!!\n",
    "    #X = BatchNormalization(axis=3, name='bn3')(X)\n",
    "    #X = Activation('relu',name='relu_3')(X)\n",
    "    \n",
    "    \n",
    "    #X = Conv2D(80, (10, 1), strides=(1, 1), dilation_rate=(5, 1), padding='valid', name='conv4_TC')(X)    #IL FILTRO ERA 13 13 !!!!\n",
    "    #X = BatchNormalization(axis=3, name='bn4')(X)\n",
    "    #X = Activation('relu',name='relu_4')(X)\n",
    "\n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(96, (1, 18), strides=(1, 1), padding = 'valid', name='conv3')(X)    #IL FILTRO ERA 13 13 !!!!\n",
    "    X = BatchNormalization(axis=3, name='bn3')(X)\n",
    "    X = Activation('relu',name='relu_3')(X)\n",
    "\n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((1, 2), name='max_pool3')(X)\n",
    "    \n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(128, (1, 22), strides=(1, 1), padding = 'valid', name='conv4')(X)    #IL FILTRO ERA 13 13 !!!!\n",
    "    X = BatchNormalization(axis=3, name='bn4')(X)\n",
    "    X = Activation('relu',name='relu_4')(X)\n",
    "\n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((1, 2), name='max_pool4')(X)\n",
    "    \n",
    "    \n",
    "   \n",
    "\n",
    "    # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(256, activation='relu', name='fc1')(X)\n",
    "    X = Dense(1, activation='sigmoid', name='fc2')(X)\n",
    "\n",
    "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
    "    model = Model(inputs=X_input, outputs=X, name='HappyModel')\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Patient = 2\n",
    "sampling_rate = 250\n",
    "#seizure_start_s = 180\n",
    "#seizure_post = 180\n",
    "#seizure_start = sampling_rate * seizure_start_s\n",
    "#working_dir = '/content/drive/My Drive/ECG_data/'\n",
    "#working_dir = 'ECG_data/'\n",
    "#working_dir = '../MATLAB/Matlab/ECG/Script/workspace/Subjects2'\n",
    "\n",
    "\n",
    "false_positive = 0\n",
    "training_complete = 0\n",
    "seizure_available = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as scp\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(1000000, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(1000000, 1)\n"
     ]
    }
   ],
   "source": [
    "loading_file = '../MATLAB/Matlab/ECG/Script/workspace/Subjects2/16273_1.mat'\n",
    "data_training = scp.loadmat(loading_file)\n",
    "#data_training = data_training['val']\n",
    "data_on = data_training['val'].transpose()\n",
    "\n",
    "loading_file2 = '../MATLAB/Matlab/ECG/Script/workspace/Subjects2/06m.mat'\n",
    "data_training = scp.loadmat(loading_file2)\n",
    "data_off = data_training['val'].transpose()\n",
    "\n",
    "print(type(data_on))\n",
    "print(data_on.shape)\n",
    "print(type(data_off))\n",
    "print(data_off.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/mazzoni/workspace/TCNs/keras_ECG.ipynb Cell 7\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/mazzoni/workspace/TCNs/keras_ECG.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m24.0\u001b[39m, \u001b[39m8.0\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mazzoni/workspace/TCNs/keras_ECG.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(data_on\u001b[39m.\u001b[39mflatten()[\u001b[39m500000\u001b[39m:\u001b[39m520000\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mazzoni/workspace/TCNs/keras_ECG.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mgrid()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(24.0, 8.0))\n",
    "plt.plot(data_on.flatten()[500000:520000])\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(24.0, 8.0))\n",
    "plt.plot(data_off.flatten()[500000:520000])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF CHANNELS 1\n",
      "IMAGE SIZE =  2500\n",
      "IMAGE OVERLAP =  1250\n",
      "TRAINING DATA SIZE (%) 90.0\n",
      "\n",
      " \n",
      "\n",
      "DATA LENGTH OFF =  1000000\n",
      "NUMBER OF IMAGES OFF =  799\n",
      "DATA RESIZE SHAPE =  (799, 2500, 1, 1)\n",
      "label_images off length 799\n",
      "N_images_training =   719\n",
      "training_data_off size =   (719, 2500, 1, 1)\n",
      "training_label_off size = \n",
      "   (719, 1)\n",
      "N_images_testing =   80\n",
      "testing_data_off size =    (80, 2500, 1, 1)\n",
      "testing_label_off size =   (80, 1)\n",
      "DATA ON \n",
      " \n",
      "\n",
      "data_on_size original (1000000, 1)\n",
      "DATA LENGTH ON =  1000000\n",
      "NUMBER OF IMAGES ON =  799\n",
      "DATA RESIZE SHAPE =  (799, 2500, 1, 1)\n",
      "label_images on length 799\n",
      "N_images_training =   719\n",
      "training_data_on size =  (719, 2500, 1, 1)\n",
      "trainig_label_on size =   (719, 1)\n",
      "N_images_testing =   80\n",
      "testing_data_on size =  (80, 2500, 1, 1)\n",
      "testing_label_on size =   (80, 1)\n",
      "X_train shape: (1438, 2500, 1, 1)\n",
      "Y_train shape: (1438, 1)\n",
      "X_test shape: (160, 2500, 1, 1)\n",
      "Y_test shape: (160, 1)\n",
      "X_train2 shape: (1438, 1, 2500, 1)\n",
      "Y_train2 shape: (1438, 1)\n",
      "X_test2 shape: (160, 1, 2500, 1)\n",
      "Y_test2 shape: (160, 1)\n"
     ]
    }
   ],
   "source": [
    "sample = 250*10  #SIZE OF THE IMAGE.. IMAGE IS sample x nchannels  long image 1024\n",
    "overlap = 250*5   #if sample is 250*10 and overlap is 250*5 => overlap 50%  #best 384 long image  960\n",
    "training_amount = 0.90  #optimal number of epochs to train #best 0.85    #CHECK FOR OVERFITTING!!!! \n",
    "NUMBER_OF_CHANNELS = data_on.shape[1]\n",
    "print(\"NUMBER OF CHANNELS\", NUMBER_OF_CHANNELS)\n",
    "\n",
    "\n",
    "#CREA LABEL PER DATi ON E OFF\n",
    "\n",
    "label_off = np.zeros((data_off.shape[0],1))\n",
    "label_on = np.ones((data_on.shape[0],1))\n",
    "\n",
    "print(\"IMAGE SIZE = \", sample)\n",
    "print(\"IMAGE OVERLAP = \", overlap)\n",
    "print(\"TRAINING DATA SIZE (%)\", training_amount * 100)\n",
    "print(\"\\n \\n\")\n",
    "\n",
    "\n",
    "\n",
    "L_total = data_off.shape[0];\n",
    "N_imm = (L_total - sample)/(sample - overlap) +1 \n",
    "#N_imm = (L_total - overlap)/(sample - overlap) #number of windows\n",
    "n_images  = math.floor(N_imm)\n",
    "\n",
    "\n",
    "# ========================================================\n",
    "# CREO TENSORE E FACCIO NUMERO IMMAGINI PER data_off\n",
    "# ========================================================\n",
    "\n",
    "print(\"DATA LENGTH OFF = \", L_total)\n",
    "print(\"NUMBER OF IMAGES OFF = \" , n_images)\n",
    "\n",
    "data_off_r = np.zeros([n_images,sample,NUMBER_OF_CHANNELS,1])\n",
    "stride = sample - overlap\n",
    "for i in range(0,n_images): \n",
    "    data_off_r[i,0:sample,0:NUMBER_OF_CHANNELS,0] = data_off[(i*stride):(i*stride + sample),:]  #control the ovelaps [(i*stride):(i*stride + sample),:]\n",
    "\n",
    "label_images_off = label_off[:(L_total-sample + 1):(sample - overlap)]    \n",
    "print(\"DATA RESIZE SHAPE = \", data_off_r.shape)\n",
    "print(\"label_images off length\",label_images_off.shape[0])\n",
    "\n",
    "# ========================================================\n",
    "#DIVIDO TESTSET E TRAINING SET PER DATA OFF\n",
    "# ========================================================\n",
    "\n",
    "\n",
    "N_images_training_off = int(np.floor(data_off_r.shape[0]*training_amount))\n",
    "data_training_off = data_off_r[:N_images_training_off , :]\n",
    "label_training_off = label_images_off[:N_images_training_off , :]\n",
    "\n",
    "print(\"N_images_training =  \", N_images_training_off)\n",
    "print(\"training_data_off size =  \", data_training_off.shape)\n",
    "print(\"training_label_off size = \\n  \", label_training_off.shape)\n",
    "\n",
    "\n",
    "#ed il 30% per il testing\n",
    "N_images_testing_off =  n_images - N_images_training_off\n",
    "data_testing_off = data_off_r[N_images_training_off : , :]\n",
    "label_testing_off = label_images_off[N_images_training_off : , :]\n",
    "\n",
    "print(\"N_images_testing =  \", N_images_testing_off)\n",
    "print(\"testing_data_off size =   \", data_testing_off.shape) \n",
    "print(\"testing_label_off size =  \", label_testing_off.shape)    \n",
    "\n",
    "\n",
    "# ========================================================\n",
    "# CREO TENSORE E FACCIO NUMERO IMMAGINI PER data_on\n",
    "# ========================================================\n",
    "\n",
    "print(\"DATA ON \\n \\n\")\n",
    "print(\"data_on_size original\", data_on.shape)\n",
    "\n",
    "L_total = data_on.shape[0];\n",
    "N_imm = (L_total - sample)/(sample - overlap) +1 \n",
    "n_images  = math.floor(N_imm)\n",
    "\n",
    "print(\"DATA LENGTH ON = \", L_total)\n",
    "print(\"NUMBER OF IMAGES ON = \" , n_images)\n",
    "\n",
    "data_on_r = np.zeros([n_images,sample,NUMBER_OF_CHANNELS,1])\n",
    "stride = sample - overlap\n",
    "for i in range(0,n_images): \n",
    "    data_on_r[i,0:sample,0:NUMBER_OF_CHANNELS,0] = data_on[(i*stride):(i*stride + sample),:]  #control the ovelaps [(i*stride):(i*stride + sample),:]\n",
    "\n",
    "label_images_on = label_on[:(L_total-sample + 1):(sample - overlap)]\n",
    "print(\"DATA RESIZE SHAPE = \", data_on_r.shape)\n",
    "print(\"label_images on length\",label_images_on.shape[0])\n",
    "\n",
    "# ========================================================\n",
    "#DIVIDO TESTSET E TRAINING SET PER DATA ON\n",
    "# ========================================================          \n",
    "\n",
    "N_images_training_on = int(np.floor(data_on_r.shape[0]*training_amount))\n",
    "data_training_on = data_on_r[:N_images_training_on , :]\n",
    "label_training_on = label_images_on[:N_images_training_on , :]\n",
    "\n",
    "print(\"N_images_training =  \", N_images_training_on)\n",
    "print(\"training_data_on size = \", data_training_on.shape)\n",
    "print(\"trainig_label_on size =  \", label_training_on.shape)\n",
    "\n",
    "#ed il 30% per il testing\n",
    "N_images_testing_on =  n_images - N_images_training_on\n",
    "data_testing_on = data_on_r[N_images_training_on : , :]\n",
    "label_testing_on = label_images_on[N_images_training_on : , :]\n",
    "\n",
    "print(\"N_images_testing =  \", N_images_testing_on)\n",
    "print(\"testing_data_on size = \", data_testing_on.shape) \n",
    "print(\"testing_label_on size =  \", label_testing_on.shape)\n",
    "\n",
    "\n",
    "# ========================================================\n",
    "# concateno DATI TRAIN (OFF ON) e DATI TEST (OFF ON)\n",
    "# ========================================================\n",
    "\n",
    "# y are the labels\n",
    "\n",
    "X_train = np.concatenate((data_training_off,data_training_on), axis = 0)\n",
    "y_train = np.concatenate((label_training_off,label_training_on), axis = 0)\n",
    "\n",
    "X_test = np.concatenate((data_testing_off,data_testing_on), axis = 0)\n",
    "y_test = np.concatenate((label_testing_off,label_testing_on), axis = 0)\n",
    "\n",
    "\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(y_test.shape))\n",
    "\n",
    "X_train2 = X_train\n",
    "y_train2 = y_train\n",
    "\n",
    "X_test2 = X_test\n",
    "y_test2 = y_test\n",
    "\n",
    "# ========================================================\n",
    "# RESHAPING\n",
    "# ========================================================\n",
    "\n",
    "X_train2 = X_train2.transpose((0, 3, 1,2))\n",
    "X_test2 = X_test2.transpose((0, 3, 1,2))\n",
    "\n",
    "print (\"X_train2 shape: \" + str(X_train2.shape))\n",
    "print (\"Y_train2 shape: \" + str(y_train2.shape))\n",
    "print (\"X_test2 shape: \" + str(X_test2.shape))\n",
    "print (\"Y_test2 shape: \" + str(y_test2.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"HappyModel\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 1, 2500, 1)]      0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 1, 2500, 1)        8         \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 1, 2500, 1)        4         \n",
      "_________________________________________________________________\n",
      "relu_0 (Activation)          (None, 1, 2500, 1)        0         \n",
      "_________________________________________________________________\n",
      "avg_pool0 (AveragePooling2D) (None, 1, 1250, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 1, 625, 64)        704       \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 1, 625, 64)        256       \n",
      "_________________________________________________________________\n",
      "relu_1 (Activation)          (None, 1, 625, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pool1 (MaxPooling2D)     (None, 1, 312, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 1, 312, 80)        66640     \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 1, 312, 80)        320       \n",
      "_________________________________________________________________\n",
      "relu_2 (Activation)          (None, 1, 312, 80)        0         \n",
      "_________________________________________________________________\n",
      "max_pool2 (MaxPooling2D)     (None, 1, 156, 80)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 1, 139, 96)        138336    \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (None, 1, 139, 96)        384       \n",
      "_________________________________________________________________\n",
      "relu_3 (Activation)          (None, 1, 139, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pool3 (MaxPooling2D)     (None, 1, 69, 96)         0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 1, 48, 128)        270464    \n",
      "_________________________________________________________________\n",
      "bn4 (BatchNormalization)     (None, 1, 48, 128)        512       \n",
      "_________________________________________________________________\n",
      "relu_4 (Activation)          (None, 1, 48, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pool4 (MaxPooling2D)     (None, 1, 24, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,264,573\n",
      "Trainable params: 1,263,835\n",
      "Non-trainable params: 738\n",
      "_________________________________________________________________\n",
      "Epoch 1/70\n",
      "45/45 - 12s - loss: 0.0306 - accuracy: 0.9819 - val_loss: 2.8779e-07 - val_accuracy: 1.0000\n",
      "Epoch 2/70\n",
      "45/45 - 9s - loss: 0.0049 - accuracy: 0.9993 - val_loss: 7.4162 - val_accuracy: 0.5000\n",
      "Epoch 3/70\n",
      "45/45 - 9s - loss: 9.2470e-06 - accuracy: 1.0000 - val_loss: 9.1423 - val_accuracy: 0.5000\n",
      "Epoch 4/70\n",
      "45/45 - 9s - loss: 5.8239e-06 - accuracy: 1.0000 - val_loss: 7.4940 - val_accuracy: 0.5000\n",
      "Epoch 5/70\n",
      "45/45 - 9s - loss: 4.2473e-06 - accuracy: 1.0000 - val_loss: 5.6651 - val_accuracy: 0.5000\n",
      "Epoch 6/70\n",
      "45/45 - 9s - loss: 6.8506e-06 - accuracy: 1.0000 - val_loss: 3.6436 - val_accuracy: 0.5000\n",
      "Epoch 7/70\n",
      "45/45 - 9s - loss: 2.9873e-06 - accuracy: 1.0000 - val_loss: 1.1592 - val_accuracy: 0.5875\n",
      "Epoch 8/70\n",
      "45/45 - 11s - loss: 2.1699e-06 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
      "Epoch 9/70\n",
      "45/45 - 10s - loss: 4.2581e-06 - accuracy: 1.0000 - val_loss: 1.1253e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/70\n",
      "45/45 - 10s - loss: 1.8496e-06 - accuracy: 1.0000 - val_loss: 1.0488e-08 - val_accuracy: 1.0000\n",
      "Epoch 11/70\n",
      "45/45 - 10s - loss: 1.0723e-05 - accuracy: 1.0000 - val_loss: 2.3248e-09 - val_accuracy: 1.0000\n",
      "Epoch 12/70\n",
      "45/45 - 10s - loss: 1.7673e-06 - accuracy: 1.0000 - val_loss: 3.2961e-09 - val_accuracy: 1.0000\n",
      "Epoch 13/70\n",
      "45/45 - 10s - loss: 9.2819e-07 - accuracy: 1.0000 - val_loss: 4.9644e-09 - val_accuracy: 1.0000\n",
      "Epoch 14/70\n",
      "45/45 - 9s - loss: 1.2896e-06 - accuracy: 1.0000 - val_loss: 6.0695e-09 - val_accuracy: 1.0000\n",
      "Epoch 15/70\n",
      "45/45 - 9s - loss: 2.0698e-06 - accuracy: 1.0000 - val_loss: 6.9735e-09 - val_accuracy: 1.0000\n",
      "Epoch 16/70\n",
      "45/45 - 10s - loss: 1.5616e-06 - accuracy: 1.0000 - val_loss: 6.9277e-09 - val_accuracy: 1.0000\n",
      "Epoch 17/70\n",
      "45/45 - 9s - loss: 6.1748e-07 - accuracy: 1.0000 - val_loss: 7.2008e-09 - val_accuracy: 1.0000\n",
      "Epoch 18/70\n",
      "45/45 - 9s - loss: 9.2763e-07 - accuracy: 1.0000 - val_loss: 7.5136e-09 - val_accuracy: 1.0000\n",
      "Epoch 19/70\n",
      "45/45 - 9s - loss: 1.0602e-06 - accuracy: 1.0000 - val_loss: 6.9463e-09 - val_accuracy: 1.0000\n",
      "Epoch 20/70\n",
      "45/45 - 9s - loss: 6.9482e-07 - accuracy: 1.0000 - val_loss: 7.1197e-09 - val_accuracy: 1.0000\n",
      "Epoch 21/70\n",
      "45/45 - 9s - loss: 9.3346e-07 - accuracy: 1.0000 - val_loss: 6.9785e-09 - val_accuracy: 1.0000\n",
      "Epoch 22/70\n",
      "45/45 - 9s - loss: 3.6247e-07 - accuracy: 1.0000 - val_loss: 7.0095e-09 - val_accuracy: 1.0000\n",
      "Epoch 23/70\n",
      "45/45 - 9s - loss: 8.7220e-07 - accuracy: 1.0000 - val_loss: 6.3012e-09 - val_accuracy: 1.0000\n",
      "Epoch 24/70\n",
      "45/45 - 10s - loss: 4.8737e-07 - accuracy: 1.0000 - val_loss: 6.2032e-09 - val_accuracy: 1.0000\n",
      "Epoch 25/70\n",
      "45/45 - 9s - loss: 4.8013e-07 - accuracy: 1.0000 - val_loss: 5.8413e-09 - val_accuracy: 1.0000\n",
      "Epoch 26/70\n",
      "45/45 - 9s - loss: 9.3211e-07 - accuracy: 1.0000 - val_loss: 5.5392e-09 - val_accuracy: 1.0000\n",
      "Epoch 27/70\n",
      "45/45 - 9s - loss: 1.4287e-06 - accuracy: 1.0000 - val_loss: 4.6079e-09 - val_accuracy: 1.0000\n",
      "Epoch 28/70\n",
      "45/45 - 9s - loss: 2.9890e-07 - accuracy: 1.0000 - val_loss: 4.6015e-09 - val_accuracy: 1.0000\n",
      "Epoch 29/70\n",
      "45/45 - 9s - loss: 3.0379e-06 - accuracy: 1.0000 - val_loss: 4.0401e-09 - val_accuracy: 1.0000\n",
      "Epoch 30/70\n",
      "45/45 - 9s - loss: 4.5563e-07 - accuracy: 1.0000 - val_loss: 3.4501e-09 - val_accuracy: 1.0000\n",
      "Epoch 31/70\n",
      "45/45 - 9s - loss: 7.8173e-08 - accuracy: 1.0000 - val_loss: 3.3316e-09 - val_accuracy: 1.0000\n",
      "Epoch 32/70\n",
      "45/45 - 9s - loss: 2.4379e-07 - accuracy: 1.0000 - val_loss: 3.5178e-09 - val_accuracy: 1.0000\n",
      "Epoch 33/70\n",
      "45/45 - 9s - loss: 6.3778e-07 - accuracy: 1.0000 - val_loss: 2.9931e-09 - val_accuracy: 1.0000\n",
      "Epoch 34/70\n",
      "45/45 - 9s - loss: 3.0696e-07 - accuracy: 1.0000 - val_loss: 2.9223e-09 - val_accuracy: 1.0000\n",
      "Epoch 35/70\n",
      "45/45 - 9s - loss: 3.0934e-07 - accuracy: 1.0000 - val_loss: 2.8443e-09 - val_accuracy: 1.0000\n",
      "Epoch 36/70\n",
      "45/45 - 9s - loss: 4.2550e-07 - accuracy: 1.0000 - val_loss: 2.7271e-09 - val_accuracy: 1.0000\n",
      "Epoch 37/70\n",
      "45/45 - 9s - loss: 9.4519e-07 - accuracy: 1.0000 - val_loss: 2.6069e-09 - val_accuracy: 1.0000\n",
      "Epoch 38/70\n",
      "45/45 - 9s - loss: 5.1116e-07 - accuracy: 1.0000 - val_loss: 2.4383e-09 - val_accuracy: 1.0000\n",
      "Epoch 39/70\n",
      "45/45 - 9s - loss: 1.9097e-07 - accuracy: 1.0000 - val_loss: 2.4505e-09 - val_accuracy: 1.0000\n",
      "Epoch 40/70\n",
      "45/45 - 9s - loss: 3.7393e-07 - accuracy: 1.0000 - val_loss: 2.2871e-09 - val_accuracy: 1.0000\n",
      "Epoch 41/70\n",
      "45/45 - 9s - loss: 3.6624e-07 - accuracy: 1.0000 - val_loss: 2.2689e-09 - val_accuracy: 1.0000\n",
      "Epoch 42/70\n",
      "45/45 - 10s - loss: 3.2697e-07 - accuracy: 1.0000 - val_loss: 1.9568e-09 - val_accuracy: 1.0000\n",
      "Epoch 43/70\n",
      "45/45 - 9s - loss: 4.8154e-07 - accuracy: 1.0000 - val_loss: 1.8668e-09 - val_accuracy: 1.0000\n",
      "Epoch 44/70\n",
      "45/45 - 9s - loss: 1.7356e-07 - accuracy: 1.0000 - val_loss: 1.8125e-09 - val_accuracy: 1.0000\n",
      "Epoch 45/70\n",
      "45/45 - 9s - loss: 2.3290e-06 - accuracy: 1.0000 - val_loss: 1.4181e-09 - val_accuracy: 1.0000\n",
      "Epoch 46/70\n",
      "45/45 - 9s - loss: 1.1445e-07 - accuracy: 1.0000 - val_loss: 1.3095e-09 - val_accuracy: 1.0000\n",
      "Epoch 47/70\n",
      "45/45 - 9s - loss: 7.7586e-08 - accuracy: 1.0000 - val_loss: 1.3117e-09 - val_accuracy: 1.0000\n",
      "Epoch 48/70\n",
      "45/45 - 9s - loss: 2.4171e-07 - accuracy: 1.0000 - val_loss: 1.2290e-09 - val_accuracy: 1.0000\n",
      "Epoch 49/70\n",
      "45/45 - 9s - loss: 9.8134e-08 - accuracy: 1.0000 - val_loss: 1.2163e-09 - val_accuracy: 1.0000\n",
      "Epoch 50/70\n",
      "45/45 - 9s - loss: 1.7401e-07 - accuracy: 1.0000 - val_loss: 1.1808e-09 - val_accuracy: 1.0000\n",
      "Epoch 51/70\n",
      "45/45 - 9s - loss: 6.1107e-08 - accuracy: 1.0000 - val_loss: 1.2273e-09 - val_accuracy: 1.0000\n",
      "Epoch 52/70\n",
      "45/45 - 9s - loss: 8.9467e-08 - accuracy: 1.0000 - val_loss: 1.2742e-09 - val_accuracy: 1.0000\n",
      "Epoch 53/70\n",
      "45/45 - 9s - loss: 3.9329e-07 - accuracy: 1.0000 - val_loss: 1.2310e-09 - val_accuracy: 1.0000\n",
      "Epoch 54/70\n",
      "45/45 - 9s - loss: 1.3047e-07 - accuracy: 1.0000 - val_loss: 1.0916e-09 - val_accuracy: 1.0000\n",
      "Epoch 55/70\n",
      "45/45 - 9s - loss: 1.0578e-07 - accuracy: 1.0000 - val_loss: 1.1314e-09 - val_accuracy: 1.0000\n",
      "Epoch 56/70\n",
      "45/45 - 9s - loss: 1.0103e-07 - accuracy: 1.0000 - val_loss: 1.0823e-09 - val_accuracy: 1.0000\n",
      "Epoch 57/70\n",
      "45/45 - 10s - loss: 5.6812e-08 - accuracy: 1.0000 - val_loss: 1.0531e-09 - val_accuracy: 1.0000\n",
      "Epoch 58/70\n",
      "45/45 - 9s - loss: 1.0777e-06 - accuracy: 1.0000 - val_loss: 9.0886e-10 - val_accuracy: 1.0000\n",
      "Epoch 59/70\n",
      "45/45 - 9s - loss: 7.2164e-07 - accuracy: 1.0000 - val_loss: 7.7007e-10 - val_accuracy: 1.0000\n",
      "Epoch 60/70\n",
      "45/45 - 9s - loss: 1.2940e-07 - accuracy: 1.0000 - val_loss: 7.4050e-10 - val_accuracy: 1.0000\n",
      "Epoch 61/70\n",
      "45/45 - 9s - loss: 3.7496e-08 - accuracy: 1.0000 - val_loss: 7.1694e-10 - val_accuracy: 1.0000\n",
      "Epoch 62/70\n",
      "45/45 - 9s - loss: 3.0821e-08 - accuracy: 1.0000 - val_loss: 6.9383e-10 - val_accuracy: 1.0000\n",
      "Epoch 63/70\n",
      "45/45 - 9s - loss: 9.0529e-08 - accuracy: 1.0000 - val_loss: 6.5057e-10 - val_accuracy: 1.0000\n",
      "Epoch 64/70\n",
      "45/45 - 9s - loss: 1.3334e-07 - accuracy: 1.0000 - val_loss: 6.7937e-10 - val_accuracy: 1.0000\n",
      "Epoch 65/70\n",
      "45/45 - 9s - loss: 2.6742e-08 - accuracy: 1.0000 - val_loss: 6.7744e-10 - val_accuracy: 1.0000\n",
      "Epoch 66/70\n",
      "45/45 - 9s - loss: 6.7255e-08 - accuracy: 1.0000 - val_loss: 6.5431e-10 - val_accuracy: 1.0000\n",
      "Epoch 67/70\n",
      "45/45 - 9s - loss: 2.9364e-07 - accuracy: 1.0000 - val_loss: 6.2552e-10 - val_accuracy: 1.0000\n",
      "Epoch 68/70\n",
      "45/45 - 9s - loss: 6.3001e-08 - accuracy: 1.0000 - val_loss: 6.0389e-10 - val_accuracy: 1.0000\n",
      "Epoch 69/70\n",
      "45/45 - 9s - loss: 1.6525e-08 - accuracy: 1.0000 - val_loss: 6.1048e-10 - val_accuracy: 1.0000\n",
      "Epoch 70/70\n",
      "45/45 - 9s - loss: 2.0151e-07 - accuracy: 1.0000 - val_loss: 5.8084e-10 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ========================================================\n",
    "# NETWORK TRAINING\n",
    "# ========================================================\n",
    "\n",
    "  \n",
    "      \n",
    "net = Net(X_train2.shape[1:])   \n",
    "    \n",
    "net.summary()\n",
    "#opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "#net.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "net.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "history = net.fit(X_train2, y_train2, epochs=70, verbose=2, batch_size=32,validation_data = (X_test2,y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(16, 12)) #figsize weight*high \n",
    "ax.grid(False)\n",
    "disp = ConfusionMatrixDisplay.from_predictions(\n",
    "    #y_test,\n",
    "    #y_pred_test, \n",
    "    y_train,\n",
    "    y_test,\n",
    "    normalize=\"true\",\n",
    "    #display_labels=list(action_dict.keys()),\n",
    "    display_label=('regular', 'irregular'),\n",
    "    xticks_rotation=45,\n",
    "    values_format=\".3f\",\n",
    "    ax=ax,\n",
    ")\n",
    "disp.ax_.set_title(f\"Test results (subject {SUBJECT} {MVC}% MVC)\")\n",
    "plt.show()\n",
    "#plt.savefig(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Mar 13 2023, 10:26:41) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
